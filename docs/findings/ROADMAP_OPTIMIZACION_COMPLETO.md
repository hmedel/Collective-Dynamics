# Roadmap de Optimizaci√≥n Completo - CollectiveDynamics.jl

**Fecha:** 2025-11-13
**Objetivos del Usuario:**
1. ‚úÖ Aumentar precisi√≥n (mejor conservaci√≥n de energ√≠a/momento)
2. ‚úÖ Escalar a m√°s part√≠culas (N >> 100)
3. ‚úÖ Generalizar a curvas 3D embebidas en ‚Ñù¬≥ (curvatura + torsi√≥n)

**Estado actual:**
- ‚úÖ Paralelizaci√≥n CPU (colisiones): 2-8x speedup
- ‚úÖ Conservaci√≥n: ŒîE/E‚ÇÄ ~ 1e-6 con Float64
- ‚ö†Ô∏è L√≠mite pr√°ctico: N ~ 100 part√≠culas (O(N¬≤) domina)
- ‚ö†Ô∏è C√≥digo espec√≠fico para elipse (2D)

---

## Fase 1: Optimizaciones Inmediatas (1-2 semanas)

### Objetivo: Preparar infraestructura para escalar

#### 1.1 Preallocaci√≥n de Memoria ‚≠ê PRIORIDAD ALTA
**Speedup:** ~1.1-1.2x
**Esfuerzo:** Bajo (2-3 horas)
**Impacto a futuro:** Cr√≠tico para N grande

**Problema actual:**
```julia
# simulate_ellipse_adaptive usa push! din√°mico
particles_history = Vector{Vector{Particle{T}}}()
push!(particles_history, copy(particles))  # Realoca cada vez
```

**Soluci√≥n:**
```julia
# Preallocaci√≥n basada en estimaci√≥n
expected_saves = ceil(Int, max_time / save_interval) + 100
particles_history = Vector{Vector{Particle{T}}}(undef, expected_saves)

# √çndice manual
save_idx = 1
particles_history[save_idx] = copy(particles)
save_idx += 1

# Si se queda corto, resize! (raro)
```

**Beneficios:**
- ~10-20% menos allocations
- Menos GC pauses (cr√≠tico para sims largas)
- Predictibilidad de memoria

**Archivo a modificar:** `src/CollectiveDynamics.jl:424-435`

---

#### 1.2 Memory Pool para Particle Arrays ‚≠ê PRIORIDAD MEDIA
**Speedup:** ~1.05-1.1x
**Esfuerzo:** Medio (1 d√≠a)

**Problema:** Cada `copy(particles)` aloca nuevo array.

**Soluci√≥n:**
```julia
# Nuevo archivo: src/memory_pool.jl
struct ParticlePool{T <: AbstractFloat}
    pool::Vector{Vector{Particle{T}}}
    in_use::BitVector
    size::Int
end

function ParticlePool{T}(max_snapshots::Int, n_particles::Int) where T
    pool = [Vector{Particle{T}}(undef, n_particles) for _ in 1:max_snapshots]
    in_use = falses(max_snapshots)
    ParticlePool{T}(pool, in_use, n_particles)
end

function acquire!(pool::ParticlePool{T}) where T
    idx = findfirst(.!pool.in_use)
    isnothing(idx) && error("Pool exhausted")
    pool.in_use[idx] = true
    return pool.pool[idx], idx
end

function release!(pool::ParticlePool, idx::Int)
    pool.in_use[idx] = false
end

# Uso en simulate_ellipse_adaptive:
pool = ParticlePool{T}(expected_saves, length(particles))
arr, idx = acquire!(pool)
copyto!(arr, particles)  # M√°s r√°pido que copy()
particles_history[save_idx] = arr
```

**Beneficios:**
- Elimina allocations en loop principal
- ~5-10% menos tiempo en GC
- Escalable a N grande

---

#### 1.3 Reducir Allocations en Conservation ‚≠ê PRIORIDAD BAJA
**Speedup:** ~1.02-1.05x
**Esfuerzo:** Bajo (2 horas)

**Problema:**
```julia
# src/conservation.jl crea vectores intermedios
total_energy = sum(kinetic_energy_angular(p, a, b) for p in particles)
```

**Soluci√≥n:**
```julia
function compute_total_energy(particles, a, b)
    E = zero(eltype(particles[1].Œ∏))
    @inbounds for p in particles
        E += kinetic_energy_angular(p, a, b)
    end
    return E
end
```

**Beneficios:**
- Elimina allocations en comprehensions
- Marginal pero √∫til para sims largas

---

## Fase 2: Spatial Hashing (2-3 semanas) ‚≠ê‚≠ê‚≠ê CR√çTICO

### Objetivo: Romper la barrera O(N¬≤) ‚Üí O(N)

**Speedup esperado:**
- N=100: ~5-10x
- N=500: ~50-100x
- N=1000: ~100-200x

**Esfuerzo:** Alto (2-3 semanas)
**Prioridad:** üî¥ **CR√çTICA** para escalar a N>100

---

### 2.1 Dise√±o de Spatial Hash

**Concepto:**
```
Elipse (a,b) ‚Üí Grid de celdas (cell_size √ó cell_size)
Cada part√≠cula ‚Üí celda seg√∫n (x,y)
Colisiones: solo revisar pares en celdas vecinas (3√ó3 = 9 celdas)
```

**Estructura de datos:**
```julia
# Nuevo archivo: src/spatial_hash.jl

struct SpatialHash{T <: AbstractFloat}
    cell_size::T
    n_cells_x::Int
    n_cells_y::Int
    cells::Vector{Vector{Int}}  # cells[cell_idx] = [particle_indices...]

    # Bounding box de la elipse
    x_min::T
    x_max::T
    y_min::T
    y_max::T
end

function SpatialHash{T}(a::T, b::T, n_particles::Int) where T
    # Elipse: -a ‚â§ x ‚â§ a, -b ‚â§ y ‚â§ b
    x_min, x_max = -a, a
    y_min, y_max = -b, b

    # Heur√≠stica: cell_size ~ 2 √ó radio_part√≠cula_promedio
    # Para elipse con N part√≠culas uniformes:
    perimeter = œÄ * (3(a+b) - sqrt((3a+b)*(a+3b)))
    avg_spacing = perimeter / n_particles
    cell_size = 2 * avg_spacing

    n_cells_x = ceil(Int, (x_max - x_min) / cell_size)
    n_cells_y = ceil(Int, (y_max - y_min) / cell_size)

    cells = [Int[] for _ in 1:(n_cells_x * n_cells_y)]

    SpatialHash{T}(cell_size, n_cells_x, n_cells_y, cells,
                   x_min, x_max, y_min, y_max)
end

function cell_index(hash::SpatialHash{T}, x::T, y::T) where T
    # Convertir (x,y) ‚Üí (cell_x, cell_y) ‚Üí linear index
    cell_x = clamp(floor(Int, (x - hash.x_min) / hash.cell_size) + 1, 1, hash.n_cells_x)
    cell_y = clamp(floor(Int, (y - hash.y_min) / hash.cell_size) + 1, 1, hash.n_cells_y)
    return (cell_y - 1) * hash.n_cells_x + cell_x
end

function insert_particle!(hash::SpatialHash{T}, particle_idx::Int, p::Particle{T}) where T
    idx = cell_index(hash, p.pos[1], p.pos[2])
    push!(hash.cells[idx], particle_idx)
end

function clear!(hash::SpatialHash)
    for cell in hash.cells
        empty!(cell)
    end
end

function rebuild!(hash::SpatialHash{T}, particles::Vector{Particle{T}}) where T
    clear!(hash)
    @inbounds for i in 1:length(particles)
        insert_particle!(hash, i, particles[i])
    end
end

function get_neighbor_cells(hash::SpatialHash, cell_idx::Int)
    # Retornar √≠ndices de las 9 celdas vecinas (3√ó3)
    cell_x = mod(cell_idx - 1, hash.n_cells_x) + 1
    cell_y = div(cell_idx - 1, hash.n_cells_x) + 1

    neighbors = Int[]
    for dy in -1:1, dx in -1:1
        nx = cell_x + dx
        ny = cell_y + dy

        # Boundary check
        if 1 ‚â§ nx ‚â§ hash.n_cells_x && 1 ‚â§ ny ‚â§ hash.n_cells_y
            push!(neighbors, (ny - 1) * hash.n_cells_x + nx)
        end
    end

    return neighbors
end
```

---

### 2.2 Detecci√≥n de Colisiones con Spatial Hash

**Nueva funci√≥n:**
```julia
# En src/adaptive_time.jl

function find_next_collision_spatial(
    particles::Vector{Particle{T}},
    a::T,
    b::T,
    hash::SpatialHash{T};
    max_time::T = T(1e-5),
    min_dt::T = T(1e-10)
) where {T <: AbstractFloat}

    # Reconstruir hash (O(N))
    rebuild!(hash, particles)

    t_min = max_time
    pair_min = (0, 0)
    found = false

    # Para cada celda (O(N_cells))
    for (cell_idx, particle_indices) in enumerate(hash.cells)
        isempty(particle_indices) && continue

        # Obtener celdas vecinas
        neighbor_cells = get_neighbor_cells(hash, cell_idx)

        # Revisar pares dentro de esta celda y vecinas
        for i in particle_indices
            # Pares dentro de la misma celda
            for j in particle_indices
                if i < j
                    t_coll = time_to_collision(particles[i], particles[j], a, b; max_time=max_time)
                    if isfinite(t_coll) && t_coll < t_min
                        t_min = t_coll
                        pair_min = (i, j)
                        found = true
                    end
                end
            end

            # Pares con part√≠culas en celdas vecinas
            for neighbor_idx in neighbor_cells
                neighbor_idx == cell_idx && continue  # Ya revisado

                for j in hash.cells[neighbor_idx]
                    if i < j
                        t_coll = time_to_collision(particles[i], particles[j], a, b; max_time=max_time)
                        if isfinite(t_coll) && t_coll < t_min
                            t_min = t_coll
                            pair_min = (i, j)
                            found = true
                        end
                    end
                end
            end
        end
    end

    return (dt = found ? max(t_min, min_dt) : max_time,
            pair = pair_min,
            found = found)
end
```

**Complejidad:**
- Rebuild hash: O(N)
- Revisar celdas: O(N_cells) ‚âà O(N) si densidad uniforme
- Pares por celda: O(k¬≤) donde k = part√≠culas/celda ‚âà constante
- **Total: O(N)** vs O(N¬≤) actual

**Speedup esperado:**
- N=100: ~10x (100¬≤/100 = 100)
- N=1000: ~100x (1000¬≤/1000 = 1000)

---

### 2.3 Versi√≥n Paralela de Spatial Hash

**Combinar con threading:**
```julia
function find_next_collision_spatial_parallel(
    particles::Vector{Particle{T}},
    a::T,
    b::T,
    hash::SpatialHash{T};
    kwargs...
) where {T <: AbstractFloat}

    rebuild!(hash, particles)

    n_threads = Threads.nthreads()
    t_mins = fill(T(Inf), n_threads)
    pairs = [(0, 0) for _ in 1:n_threads]

    # Paralelizar sobre celdas
    Threads.@threads for cell_idx in 1:length(hash.cells)
        tid = Threads.threadid()

        # ... revisar colisiones en celda cell_idx ...

        if t_coll < t_mins[tid]
            t_mins[tid] = t_coll
            pairs[tid] = (i, j)
        end
    end

    # Reducci√≥n
    t_min, idx = findmin(t_mins)

    return (dt = t_min, pair = pairs[idx], found = isfinite(t_min))
end
```

**Speedup combinado (Spatial + Parallel):**
- N=1000: ~100x (spatial) √ó 10x (parallel) = **1000x** üöÄ

---

### 2.4 Integraci√≥n en simulate_ellipse_adaptive

```julia
function simulate_ellipse_adaptive(
    particles_initial::Vector{Particle{T}},
    a::T,
    b::T;
    use_spatial_hash::Bool = true,  # Nuevo par√°metro
    use_parallel::Bool = false,
    kwargs...
) where {T <: AbstractFloat}

    particles = copy(particles_initial)
    n = length(particles)

    # Decidir m√©todo de colisi√≥n
    if use_spatial_hash && n > 50
        hash = SpatialHash{T}(a, b, n)

        collision_finder = if use_parallel && Threads.nthreads() > 1
            (particles, a, b) -> find_next_collision_spatial_parallel(particles, a, b, hash; kwargs...)
        else
            (particles, a, b) -> find_next_collision_spatial(particles, a, b, hash; kwargs...)
        end
    else
        # Fallback a O(N¬≤) original
        collision_finder = use_parallel ? find_next_collision_parallel : find_next_collision
    end

    # Loop principal
    while t < max_time
        collision_info = collision_finder(particles, a, b)
        # ... resto igual ...
    end
end
```

---

## Fase 3: Generalizaci√≥n a Curvas 3D (1-2 meses)

### Objetivo: Preparar c√≥digo para curvas en ‚Ñù¬≥

**Cambios arquitect√≥nicos necesarios:**

#### 3.1 Abstracci√≥n de Geometr√≠a

**Crear interfaz gen√©rica:**
```julia
# Nuevo archivo: src/geometry/manifold.jl

abstract type Manifold{T <: AbstractFloat, N} end  # N = dimensi√≥n par√°metro

# Curva en R¬≥: N=1 (par√°metro s), embedded en R¬≥
struct Curve3D{T} <: Manifold{T, 1}
    # Funciones que definen la curva
    position::Function      # s ‚Üí (x,y,z)
    tangent::Function       # s ‚Üí T (vector tangente)
    normal::Function        # s ‚Üí N (vector normal)
    binormal::Function      # s ‚Üí B (vector binormal)
    curvature::Function     # s ‚Üí Œ∫(s)
    torsion::Function       # s ‚Üí œÑ(s)
    arc_length::T           # Longitud total de la curva
end

# Elipse actual: caso especial
struct Ellipse2D{T} <: Manifold{T, 1}
    a::T  # Semi-eje mayor
    b::T  # Semi-eje menor
end

# Interface com√∫n
function metric(m::Manifold{T}, params...) where T
    error("Not implemented for $(typeof(m))")
end

function christoffel(m::Manifold{T}, params...) where T
    error("Not implemented for $(typeof(m))")
end

function cartesian_position(m::Manifold{T}, params...) where T
    error("Not implemented for $(typeof(m))")
end

# Implementaci√≥n para Ellipse2D
function metric(m::Ellipse2D{T}, Œ∏::T) where T
    return metric_ellipse(Œ∏, m.a, m.b)
end

function christoffel(m::Ellipse2D{T}, Œ∏::T) where T
    return christoffel_ellipse(Œ∏, m.a, m.b)
end

function cartesian_position(m::Ellipse2D{T}, Œ∏::T) where T
    return cartesian_from_angle(Œ∏, m.a, m.b)
end

# Implementaci√≥n para Curve3D
function metric(m::Curve3D{T}, s::T) where T
    # g_ss = |dr/ds|¬≤ (para curva parametrizada por longitud de arco = 1)
    return one(T)
end

function christoffel(m::Curve3D{T}, s::T) where T
    # Œì^s_ss = Œ∫(s) * n_tangent / |tangent|¬≤
    # Para curva parametrizada por arc length: simplificado
    Œ∫ = m.curvature(s)
    return Œ∫
end

function cartesian_position(m::Curve3D{T}, s::T) where T
    return m.position(s)
end
```

---

#### 3.2 Part√≠cula Gen√©rica

```julia
# Modificar src/particles.jl

struct Particle{T <: AbstractFloat, N}  # N = dim par√°metro
    id::Int32
    mass::T
    radius::T

    # Coordenadas en el espacio par√°metro
    q::SVector{N, T}        # Œ∏ para elipse, s para curva 3D
    q_dot::SVector{N, T}    # Œ∏Ãá para elipse, ·π° para curva 3D

    # Coordenadas cartesianas (R¬≤ para elipse, R¬≥ para curva 3D)
    pos::SVector{3, T}      # Siempre R¬≥ (z=0 para curvas planas)
    vel::SVector{3, T}
end

# Constructores especializados
function Particle(id::Int, mass::T, radius::T, Œ∏::T, Œ∏_dot::T,
                  pos::SVector{2,T}, vel::SVector{2,T}) where T
    # Caso 2D: convertir a 3D con z=0
    pos3d = SVector{3,T}(pos[1], pos[2], zero(T))
    vel3d = SVector{3,T}(vel[1], vel[2], zero(T))

    return Particle{T, 1}(id, mass, radius,
                         SVector{1,T}(Œ∏), SVector{1,T}(Œ∏_dot),
                         pos3d, vel3d)
end
```

---

#### 3.3 Integrador Gen√©rico

```julia
# Modificar src/integrators/forest_ruth.jl

function forest_ruth_step(
    q::SVector{N, T},
    q_dot::SVector{N, T},
    dt::T,
    manifold::Manifold{T, N}
) where {T, N}

    coeffs = get_coefficients(T)

    # Paso 1
    q1 = q .+ coeffs.Œ≥‚ÇÅ * dt .* q_dot
    Œì1 = christoffel(manifold, q1...)
    q_dot1 = q_dot .- coeffs.œÅ‚ÇÅ * dt .* Œì1 .* q_dot .* q_dot

    # Pasos 2, 3, 4 similar...

    return q4, q_dot4
end

# Versi√≥n espec√≠fica para elipse (backward compatibility)
function forest_ruth_step_ellipse(Œ∏::T, Œ∏_dot::T, dt::T, a::T, b::T) where T
    manifold = Ellipse2D{T}(a, b)
    q = SVector{1,T}(Œ∏)
    q_dot = SVector{1,T}(Œ∏_dot)

    q_new, q_dot_new = forest_ruth_step(q, q_dot, dt, manifold)

    return q_new[1], q_dot_new[1]
end
```

---

#### 3.4 Ejemplo: H√©lice en R¬≥

```julia
# examples/helix_simulation.jl

using CollectiveDynamics

# Definir h√©lice: (a*cos(s), a*sin(s), b*s)
function helix_position(s::T, a::T, b::T) where T
    return SVector{3,T}(a*cos(s), a*sin(s), b*s)
end

function helix_tangent(s::T, a::T, b::T) where T
    # dr/ds
    return SVector{3,T}(-a*sin(s), a*cos(s), b)
end

function helix_curvature(s::T, a::T, b::T) where T
    # Œ∫ = a / (a¬≤ + b¬≤)
    return a / (a^2 + b^2)
end

function helix_torsion(s::T, a::T, b::T) where T
    # œÑ = b / (a¬≤ + b¬≤)
    return b / (a^2 + b^2)
end

# Crear manifold
a, b = 1.0, 0.5
arc_length = 4œÄ  # 2 vueltas

helix = Curve3D{Float64}(
    s -> helix_position(s, a, b),
    s -> helix_tangent(s, a, b),
    s -> helix_normal(s, a, b),      # Calcular con Frenet-Serret
    s -> helix_binormal(s, a, b),    # B = T √ó N
    s -> helix_curvature(s, a, b),
    s -> helix_torsion(s, a, b),
    arc_length
)

# Generar part√≠culas en la h√©lice
particles = generate_random_particles(30, 1.0, 0.1, helix)

# Simular
data = simulate_manifold_adaptive(particles, helix;
                                  max_time=1.0,
                                  dt_max=1e-5)
```

---

## Fase 4: Aumentar Precisi√≥n (en paralelo con Fase 2-3)

### Objetivo: Mejorar conservaci√≥n de cantidades

**Opciones:**

#### 4.1 Float64 ‚Üí BigFloat (Precisi√≥n Arbitraria)
**Conservaci√≥n:** ŒîE/E‚ÇÄ ~ 1e-15 o mejor
**Speedup:** **0.01-0.1x** ‚ùå (10-100x m√°s lento)
**Uso:** Solo para validaci√≥n, no producci√≥n

```julia
# Config TOML
[simulation]
precision = "BigFloat"  # "Float64", "Float32", "BigFloat"
```

---

#### 4.2 Double-Double o Quad-Double (DoubleFloats.jl)
**Conservaci√≥n:** ŒîE/E‚ÇÄ ~ 1e-30
**Speedup:** **0.1-0.3x** (3-10x m√°s lento)
**Uso:** Balance razonable precisi√≥n/velocidad

```julia
using DoubleFloats

T = Double64  # ~32 d√≠gitos de precisi√≥n
particles = generate_random_particles(30, T(1.0), T(0.05), T(2.0), T(1.0))
```

---

#### 4.3 Integradores de Mayor Orden
**Conservaci√≥n:** Mejor que Forest-Ruth 4¬∫ orden
**Speedup:** ~0.5-0.8x (m√°s pasos internos)

**Opciones:**
- **Yoshida 6¬∫ orden:** Error O(dt‚Å∂)
- **Forest-Ruth 8¬∫ orden:** Error O(dt‚Å∏)
- **Adaptive Runge-Kutta:** RK45, RK78 con control de error

```julia
# Nuevo archivo: src/integrators/yoshida6.jl

function yoshida6_step(q, q_dot, dt, manifold)
    # Coeficientes Yoshida 6¬∫ orden (8 sub-pasos)
    w1 = -1.17767998417887
    w2 = 0.235573213359357
    w3 = 0.784513610477560
    w0 = 1 - 2*(w1 + w2 + w3)

    # 8 pasos Forest-Ruth b√°sicos con coeficientes especiales
    # ...
end
```

---

#### 4.4 Correcci√≥n de Conservaci√≥n (Projection Methods)

**Idea:** Proyectar soluci√≥n sobre variedad de energ√≠a constante cada N pasos.

```julia
function project_onto_energy_surface!(particles, E0, a, b; tolerance=1e-12)
    # Calcular energ√≠a actual
    E = total_energy(particles, a, b)
    ŒîE = E - E0

    if abs(ŒîE) > tolerance
        # Escalar velocidades para preservar energ√≠a
        scale_factor = sqrt(E0 / E)
        for i in 1:length(particles)
            p = particles[i]
            Œ∏_dot_new = p.Œ∏_dot * scale_factor
            particles[i] = update_particle(p, p.Œ∏, Œ∏_dot_new, a, b)
        end
    end
end

# Usar cada 100 pasos
if step % 100 == 0
    project_onto_energy_surface!(particles, E0, a, b)
end
```

**Ventajas:**
- Conservaci√≥n exacta (dentro de tolerancia)
- Overhead m√≠nimo (~1-2%)

**Desventajas:**
- No es "f√≠sico" (forzamos conservaci√≥n)
- Puede introducir artefactos

---

## Fase 5: GPU Acceleration (3-6 meses)

### Objetivo: Speedup masivo para N >> 1000

**Tecnolog√≠as:**
- CUDA.jl (NVIDIA GPUs)
- AMDGPU.jl (AMD GPUs)
- KernelAbstractions.jl (portable)

**Speedup esperado:**
- N=1000: ~50-100x
- N=10000: ~200-500x

**Implementaci√≥n:**
```julia
# src/gpu/collision_detection_cuda.jl

using CUDA

function find_collisions_kernel!(
    result_times::CuDeviceVector{T},
    result_pairs::CuDeviceVector{Tuple{Int,Int}},
    positions::CuDeviceMatrix{T},
    velocities::CuDeviceMatrix{T},
    radii::CuDeviceVector{T},
    n::Int,
    dt_max::T
) where T

    # Thread ID en grid 2D
    i = (blockIdx().x - 1) * blockDim().x + threadIdx().x
    j = (blockIdx().y - 1) * blockDim().y + threadIdx().y

    if i < j <= n
        # Calcular time_to_collision para par (i,j)
        t = time_to_collision_device(positions[:,i], velocities[:,i], radii[i],
                                     positions[:,j], velocities[:,j], radii[j],
                                     dt_max)

        # Atomic min para encontrar m√≠nimo global
        if isfinite(t)
            old_min = CUDA.@atomic result_times[1] = min(result_times[1], t)

            # Si este thread actualiz√≥ el m√≠nimo, guardar par
            if old_min > t
                result_pairs[1] = (i, j)
            end
        end
    end

    return nothing
end

function find_next_collision_gpu(particles::Vector{Particle{T}}, ...) where T
    n = length(particles)

    # Transferir a GPU
    positions_gpu = CuArray([p.pos for p in particles])
    velocities_gpu = CuArray([p.vel for p in particles])
    radii_gpu = CuArray([p.radius for p in particles])

    result_times = CuArray([T(Inf)])
    result_pairs = CuArray([(0, 0)])

    # Launch kernel
    threads = (16, 16)
    blocks = (cld(n, threads[1]), cld(n, threads[2]))

    @cuda threads=threads blocks=blocks find_collisions_kernel!(
        result_times, result_pairs,
        positions_gpu, velocities_gpu, radii_gpu,
        n, dt_max
    )

    # Transferir resultado a CPU
    t_min = Array(result_times)[1]
    pair = Array(result_pairs)[1]

    return (dt=t_min, pair=pair, found=isfinite(t_min))
end
```

---

## Roadmap de Implementaci√≥n Recomendado

### Mes 1-2: Optimizaciones Base
- ‚úÖ Semana 1: Preallocaci√≥n + Memory Pool
- ‚úÖ Semana 2: Reducir allocations
- ‚úÖ Semana 3-4: Tests y benchmarks
- **Resultado:** ~1.2-1.3x speedup base

### Mes 3-4: Spatial Hashing
- ‚úÖ Semana 5-6: Implementar SpatialHash
- ‚úÖ Semana 7: Versi√≥n paralela
- ‚úÖ Semana 8: Benchmarks N=100-1000
- **Resultado:** ~10-100x speedup para N>100

### Mes 5-6: Generalizaci√≥n 3D (en paralelo)
- ‚úÖ Semana 9-10: Abstracci√≥n Manifold
- ‚úÖ Semana 11: Implementar Curve3D
- ‚úÖ Semana 12: Ejemplos (h√©lice, toro, etc.)
- **Resultado:** Framework gen√©rico

### Mes 7-12: GPU (opcional, largo plazo)
- ‚úÖ Mes 7-8: CUDA.jl setup + kernels b√°sicos
- ‚úÖ Mes 9-10: Integrar con pipeline
- ‚úÖ Mes 11-12: Optimizaci√≥n y profiling
- **Resultado:** ~50-500x speedup para N>>1000

---

## Priorizaci√≥n por Caso de Uso

### Caso A: N=50-200, precisi√≥n alta, curvas 2D
**Prioridad:**
1. üî¥ Fase 4.4: Projection methods (mejor conservaci√≥n)
2. üü° Fase 1: Micro-optimizaciones
3. üü° Fase 2: Spatial hashing (preparar para escalar)

### Caso B: N=200-1000, precisi√≥n media, curvas 2D
**Prioridad:**
1. üî¥ Fase 2: Spatial hashing (cr√≠tico)
2. üü° Fase 1: Micro-optimizaciones
3. üîµ Fase 4.2: DoubleFloats (si necesitas precisi√≥n)

### Caso C: N>1000, precisi√≥n media, curvas 2D/3D
**Prioridad:**
1. üî¥ Fase 2: Spatial hashing
2. üî¥ Fase 3: Generalizaci√≥n 3D
3. üü° Fase 5: GPU (largo plazo)

### Caso D: Generalizaci√≥n 3D es prioridad
**Prioridad:**
1. üî¥ Fase 3: Abstracci√≥n Manifold
2. üü° Fase 1: Micro-optimizaciones
3. üü° Fase 2: Spatial hashing (adaptado a 3D)

---

## Siguiente Paso Recomendado

Dado tus objetivos (precisi√≥n + escalabilidad + 3D), propongo:

**Opci√≥n 1: Empezar con fundamentos (conservador)**
1. Implementar Fase 1 (1-2 semanas)
2. Implementar Fase 4.4 (projection methods, 1 semana)
3. Benchmarks para validar mejoras
4. Decidir: ¬øSpatial Hash o 3D primero?

**Opci√≥n 2: Ir directo a 3D (ambicioso)**
1. Implementar Fase 3.1-3.2 (abstracci√≥n, 2-3 semanas)
2. Implementar ejemplo h√©lice (1 semana)
3. Implementar Fase 1 en paralelo
4. Spatial hashing adaptado a 3D despu√©s

**Opci√≥n 3: Maximizar velocidad primero (pragm√°tico)**
1. Implementar Fase 2 (Spatial Hash, 2-3 semanas)
2. Benchmarks N=100-1000
3. Fase 3 (3D) despu√©s con infraestructura r√°pida
4. Proyecci√≥n de conservaci√≥n al final

---

## ¬øQu√© prefieres?

**A)** Opci√≥n 1 (fundamentos + conservaci√≥n)
**B)** Opci√≥n 2 (generalizaci√≥n 3D primero)
**C)** Opci√≥n 3 (velocidad primero, 3D despu√©s)
**D)** Otra combinaci√≥n personalizada

Basado en tu elecci√≥n, podemos empezar a implementar el primer paso ahora mismo.
